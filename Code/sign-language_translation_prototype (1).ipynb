{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77305dde-8763-46bf-abb1-4dbb3b15ca95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to match label to letter\n",
    "def getLetter(result):\n",
    "    classLabels = { 0: 'A',\n",
    "                    1: 'B',\n",
    "                    2: 'C',\n",
    "                    3: 'D',\n",
    "                    4: 'E',\n",
    "                    5: 'F',\n",
    "                    6: 'G',\n",
    "                    7: 'H',\n",
    "                    8: 'I',\n",
    "                    9: 'K',\n",
    "                    10: 'L',\n",
    "                    11: 'M',\n",
    "                    12: 'N',\n",
    "                    13: 'O',\n",
    "                    14: 'P',\n",
    "                    15: 'Q',\n",
    "                    16: 'R',\n",
    "                    17: 'S',\n",
    "                    18: 'T',\n",
    "                    19: 'U',\n",
    "                    20: 'V',\n",
    "                    21: 'W',\n",
    "                    22: 'X',\n",
    "                    23: 'Y',\n",
    "                    24: ' '}\n",
    "    try:\n",
    "        res = int(result)\n",
    "        return classLabels[res]\n",
    "    except:\n",
    "        return \"Error\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a94b654-65c3-457c-b8d5-7e5089c359c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def max(liste):\n",
    "    c=0\n",
    "    for i in range(len(liste)):\n",
    "        if liste[i]>c:\n",
    "            c=liste[i]\n",
    "    return liste.index(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd531370-070d-4e2b-a0e6-d92e3e534348",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "classifier= load_model('model_200_samples.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "064a1b5a-e9f3-43cc-a5b7-9bf2d5dc523b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_hands   = mp.solutions.hands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b8b363d-f473-4428-865c-ba97022c4b05",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Your message is :  \n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "No text to speak",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m--------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9508\\3209524408.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdestroyAllWindows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Your message is : \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m     \u001b[0mspeech\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mgtts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgTTS\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlang\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'en'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m     \u001b[0mspeech\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"audio.mp3\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"audio.mp3\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\MachineLearning\\lib\\site-packages\\gtts\\tts.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, text, tld, lang, slow, lang_check, pre_processor_funcs, tokenizer_func)\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m         \u001b[1;31m# Text\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 134\u001b[1;33m         \u001b[1;32massert\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"No text to speak\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    135\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: No text to speak"
     ]
    }
   ],
   "source": [
    "import cv2 as cv2\n",
    "import time\n",
    "import gtts\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "time_delay = 15\n",
    "\n",
    "ref = time.time()\n",
    "cap = cv2.VideoCapture(0)\n",
    "msg = \"\"\n",
    "\n",
    "with mp_hands.Hands(min_detection_confidence=0.8,min_tracking_confidence=0.5) as hands:\n",
    "    while True:\n",
    "\n",
    "        ret, frame = cap.read()\n",
    "        frame=cv2.flip(frame, 1)\n",
    "\n",
    "        #define region of interest   \n",
    "        #roi = frame[100:400, 320:620]\n",
    "        roi = frame[100:350, 320:570]\n",
    "        roi = cv2.cvtColor(roi, cv2.COLOR_BGR2RGB)\n",
    "        roi.flags.writeable= False\n",
    "        results = hands.process(roi)\n",
    "        roi.flags.writeable= True\n",
    "        #zeros=np.zeros(roi.shape)\n",
    "        if results.multi_hand_landmarks:\n",
    "            for num,hand in enumerate(results.multi_hand_landmarks):\n",
    "                zeros=np.zeros(roi.shape)\n",
    "                mp_drawing.draw_landmarks(zeros,hand,mp_hands.HAND_CONNECTIONS)\n",
    "                #cv2.imshow('hand',zeros)\n",
    "                zeros = cv2.resize(zeros, (64, 64))\n",
    "                cv2.imwrite(\"ok\" + \".jpg\", zeros)\n",
    "                zeros=cv2.imread(\"ok.jpg\",cv2.IMREAD_GRAYSCALE)\n",
    "                zeros = zeros.reshape(1,64,64,1)\n",
    "                zeros=zeros/255\n",
    "                prediction=classifier.predict(zeros, 1, verbose = 0)[0]\n",
    "                prediction=list(prediction)\n",
    "                ma = max(prediction)\n",
    "                cv2.putText(frame,getLetter(ma), (300 , 100), cv2.FONT_HERSHEY_COMPLEX, 2, (0, 255, 0), 2)\n",
    "\n",
    "        cv2.rectangle(frame, (320, 100), (570, 350), (255,0,0), 5)\n",
    "        cv2.imshow('frame', frame)\n",
    "\n",
    "        #if time.time() >= ref + time_delay:\n",
    "        if cv2.waitKey(10) == 13:   \n",
    "            msg = msg + getLetter(ma)\n",
    "            print(getLetter(ma),end=\"\")\n",
    "\n",
    "        if cv2.waitKey(10) == 32:#13 is the En ter Key\n",
    "            break\n",
    "    print() \n",
    "    cap.release()   \n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"Your message is : \",msg)\n",
    "    speech =gtts.gTTS(text=msg,lang='en')\n",
    "    speech.save(\"audio.mp3\")  \n",
    "    os.system(\"audio.mp3\")  \n",
    "    cap.release()   \n",
    "    cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
